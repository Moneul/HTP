{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minsub\\.conda\\envs\\bax\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사람의 바운딩 박스 크기로 판별하는 함수\n",
    "def person_size(results, checking_class): # 욜로 모델로 예측된 결과값과 각 객체들의 예측 클래스 번호가 담긴 리스트를 인자로 받음\n",
    "    for result in results: # 검출된 객체들을 순회\n",
    "        boxes = result.boxes # 각 객체의 bbox정보를 boxes에 할당\n",
    "\n",
    "    persons =[] # 객체들이 담긴 리스트에서 사람으로 판별된 객체 리스트의 인덱스 번호를 담을 리스트\n",
    "    bbox_sizes = [] # 바운딩 박스의 크기 정보를 담을 리스트\n",
    "\n",
    "    for idx, data in enumerate(checking_class): # 탐지된 객체들의 클래스 정보가 담긴 리스트 \n",
    "        if data == 4:  # 클래스 번호가 6일시 (\"사람\"클래스의 번호가 6임)\n",
    "            person_num = idx # 해당 리스트의 인덱스 번호를 persons리스트에 추가 \n",
    "            persons.append(person_num)\n",
    "            \n",
    "    print(persons)\n",
    "    # 사람으로 검출된 객체들의 바운딩 박스 넓이를 구해서 리스트에 추가하는 작업\n",
    "    for person_num in persons: # 사람으로 탐지된 객체의 인덱스 번호가 담긴 리스트를 순회\n",
    "        if person_num != -1:\n",
    "            person_xyxy_cordi = boxes.xyxy[person_num].tolist() # 해당 객체의 바운딩 박스의 좌상단 우하단 좌표\n",
    "            bbox_size = (person_xyxy_cordi[2] - person_xyxy_cordi[0]) * (person_xyxy_cordi[3] - person_xyxy_cordi[1]) # 좌표를 통해 바운딩 박스의 가로 세로 길이를 구해 넓이를 구함\n",
    "            bbox_sizes.append(bbox_size) # 구한 바운딩 박스 넓이를 리스트에 추가\n",
    "\n",
    "    # 가장 큰 바운딩 박스의 인덱스 찾기\n",
    "    largest_bbox_idx = bbox_sizes.index(max(bbox_sizes))\n",
    "\n",
    "    print(\"가장 큰 바운딩 박스의 인덱스:\", largest_bbox_idx)\n",
    "\n",
    "    person_num = persons[largest_bbox_idx] # 가장 넓이가 큰 바운딩 박스의 인덱스 번호로 정보 반환\n",
    "    person_num\n",
    "\n",
    "    eye_yn, leg_yn, loc, mouth_yn, size, arm_yn = person_assess(person_num, results, checking_class) # 가장큰 사람의 정보를 받아 각 요소들 라벨링하는 함수\n",
    "\n",
    "    return eye_yn, leg_yn, loc, mouth_yn, size, arm_yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검출된 객체간의 iou를 계산하는 함수\n",
    "def cal_iou(boxA, boxB):\n",
    "    \n",
    "    # boxA와 boxB의 x, y 좌표 값 중 큰 값을 선택하여 IoU 계산에 사용할 시작 좌표를 결정\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    \n",
    "    # boxA와 boxB의 x, y 좌표 값 중 작은 값을 선택하여 IoU 계산에 사용할 끝 좌표를 결정\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # 두 상자의 겹치는 영역의 넓이 계산\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # 각 상자의 전체 영역의 넓이 계산\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # iou계산\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 큰 bbox 사람의 인덱스 번호, 객체들 정보, 객체들의 클래스 리스트를 받아 각 요소들을 라벨링하는 함수\n",
    "def person_assess(person_num, results, checking_class):\n",
    "    for result in results: # 탐지된 객체들을 순회하면서\n",
    "        boxes = result.boxes # 각 객체의 bbox정보를 boxes에 할당\n",
    "\n",
    "    person_xyxy_cordi = boxes.xyxy[person_num].tolist() # 바운딩 박스의 좌상단 우하단 좌표 리스트\n",
    "    person_center_x_cordi = boxes.xywh[person_num].tolist()[0] # 바운딩 박스의 중심좌표와 가로 세로 길이 리스트\n",
    "\n",
    "    # 눈, 팔, 다리, 입, 위치, 크기\n",
    "    \n",
    "    # 눈 ============================================================\n",
    "    eye_class_num = [] # 눈 클래스의 인덱스 번호를 담을 리스트\n",
    "    for idx, data in enumerate(checking_class): # 객체들의 클래스 번호가 담긴 리스트를 순회하면서\n",
    "        if data == 1: # 리스트에 담긴 클래스 번호가 1 일시\n",
    "            eye_class_num.append(idx) # 해당 인덱스 번호를 eye_class_num에 추가\n",
    "\n",
    "    eye_xyxy_cordi = [] # 눈 바운딩 박스의 좌표 정보를 담을 리스트\n",
    "    for idx in eye_class_num: # 눈의 인덱스 번호가 담긴 리스트를 순회 하면서\n",
    "        eye_xyxy_cordi.append(boxes.xyxy[idx].tolist()) # 눈의 바운딩 박스 좌상단 우하단 좌표 리스트를 리스트에 추가\n",
    "\n",
    "    eye_iou = [] # 눈의 iou 결과값을 담을 리스트\n",
    "    for i in eye_xyxy_cordi: # 눈의 바운딩 박스 정보가 담긴 리스트를 순회\n",
    "        eye_iou.append(cal_iou(person_xyxy_cordi,i)) # 사람 바운딩 박스와 눈 바운딩 박스의 iou를 계산한 값을 리스트에 추가\n",
    "\n",
    "    eye_count = 0 # 눈의 개수 초기화\n",
    "    for i in eye_iou: # 눈와 사람의 iou값을 순회\n",
    "        if i != 0:# iou값이 0이 아니면(iou가 0일시 사람와 눈가 겹치지않음 -> 사람로 판단된 영역안에 눈가 없기에 눈로 판단된 객체가 잘못 된것이라 예측해 카운팅X)\n",
    "            eye_count += 1 # 눈의 개수 +1\n",
    "\n",
    "    eye_yn = ''  # 눈 라벨링 정보 초기화\n",
    "    if eye_count == 0: # 눈의 카운팅수가 0일시 \n",
    "        eye_yn = 'n' # 눈의 라벨링을 'n'으로 없다라고 판정\n",
    "    else:\n",
    "        eye_yn = 'y' # 눈의 라벨링을 'y'으로 있다라고 판정\n",
    "\n",
    "    # 위와 같은 과정으로 나머지 요소들도 iou를 바탕으로 사람로 판정된 영역 내에 겹치지 않는 것을 제외하고 카운팅해 라벨링\n",
    "    # 이후 요소들의 주석은 눈과 똑같기에 생략 \n",
    "    \n",
    "    # 팔 ============================================================\n",
    "    arm_class_num = []\n",
    "    for idx, data in enumerate(checking_class):\n",
    "        if data == 0:\n",
    "            arm_class_num.append(idx)\n",
    "\n",
    "    arm_xyxy_cordi = []\n",
    "    for idx in arm_class_num:\n",
    "        arm_xyxy_cordi.append(boxes.xyxy[idx].tolist())\n",
    "\n",
    "    arm_iou = []\n",
    "    for i in arm_xyxy_cordi:\n",
    "        arm_iou.append(cal_iou(person_xyxy_cordi,i))\n",
    "\n",
    "    arm_count = 0\n",
    "    for i in arm_iou:\n",
    "        if i != 0:\n",
    "            arm_count += 1\n",
    "\n",
    "    arm_yn = ''\n",
    "    if arm_count == 0:\n",
    "        arm_yn = 'n'\n",
    "    else:\n",
    "        arm_yn = 'y'\n",
    "\n",
    "    # 다리 ============================================================\n",
    "    leg_class_num = []\n",
    "    for idx, data in enumerate(checking_class):\n",
    "        if data == 2:\n",
    "            leg_class_num.append(idx)\n",
    "\n",
    "    leg_xyxy_cordi = []\n",
    "    for idx in leg_class_num:\n",
    "        leg_xyxy_cordi.append(boxes.xyxy[idx].tolist())\n",
    "\n",
    "    leg_iou = []\n",
    "    for i in leg_xyxy_cordi:\n",
    "        leg_iou.append(cal_iou(person_xyxy_cordi,i))\n",
    "\n",
    "    leg_count = 0\n",
    "    for i in leg_iou:\n",
    "        if i != 0:\n",
    "            leg_count += 1\n",
    "\n",
    "    leg_yn = ''\n",
    "    if leg_count == 0:\n",
    "        leg_yn = 'n'\n",
    "    else:\n",
    "        leg_yn = 'y'\n",
    "\n",
    "    # 입 ============================================================\n",
    "    mouth_class_num = []\n",
    "    for idx, data in enumerate(checking_class):\n",
    "        if data == 3:\n",
    "            mouth_class_num.append(idx)\n",
    "\n",
    "    mouth_xyxy_cordi = []\n",
    "    for idx in mouth_class_num:\n",
    "        mouth_xyxy_cordi.append(boxes.xyxy[idx].tolist())\n",
    "\n",
    "    mouth_iou = []\n",
    "    for i in mouth_xyxy_cordi:\n",
    "        mouth_iou.append(cal_iou(person_xyxy_cordi,i))\n",
    "\n",
    "    mouth_count = 0\n",
    "    for i in mouth_iou:\n",
    "        if i != 0:\n",
    "            mouth_count += 1\n",
    "\n",
    "    mouth_yn = ''\n",
    "    if mouth_count == 0:\n",
    "        mouth_yn = 'n'\n",
    "    else:\n",
    "        mouth_yn = 'y'\n",
    "\n",
    "    image_w = boxes.orig_shape[0] * 0.965\n",
    "    image_h = boxes.orig_shape[1]\n",
    "    image_size = image_w * image_h\n",
    "    person_size = (person_xyxy_cordi[2] - person_xyxy_cordi[0]) * (person_xyxy_cordi[3] - person_xyxy_cordi[1])\n",
    "    person_size_percent = person_size / image_size * 100\n",
    "    size = ''\n",
    "    if person_size_percent < 16 * 0.8:\n",
    "        size = 'small'\n",
    "    elif person_size_percent >= 16 * 0.8 and person_size_percent < 40 * 0.8:\n",
    "        size = 'middle'\n",
    "    elif person_size_percent >= 40 * 0.8:\n",
    "        size = 'big'\n",
    "    loc = ''\n",
    "    if person_center_x_cordi < image_w/3:\n",
    "        loc = 'left'\n",
    "    elif person_center_x_cordi >= image_w/3 and person_center_x_cordi < image_w/3*2:\n",
    "        loc = 'center'\n",
    "    elif person_center_x_cordi >= image_w/3*2:\n",
    "        loc = 'right'\n",
    "    \n",
    "    return eye_yn, leg_yn, loc, mouth_yn, size, arm_yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사람로 탐지된 객체수에 따라 라벨링을 결정\n",
    "def person_csv(results): # 객체들의 정보를 인자로 받음\n",
    "    for result in results: # 객체들을 순회하면서\n",
    "        boxes = result.boxes # 각 객체의 bbox 정보를 boxes로 할당\n",
    "    \n",
    "    checking_class = boxes.cls.int().tolist() # 각 bbox의 클래스 번호를 리스트로 반환\n",
    "\n",
    "    person_num = -1 # 사람 인덱스 번호 초기화\n",
    "    \n",
    "    for idx, data in enumerate(checking_class): # 클래스 번호가 담긴 리스트를 순회하며\n",
    "        if data == 4: # 클래스 번호가 4일시 (사람 클래스 번호가 4)\n",
    "            person_num = idx # 해당 인덱스 번호를 할당후 for문 탈출\n",
    "            break\n",
    "    \n",
    "    if person_num != -1: # 사람 인덱스 번호가 -1이 아닐시 (사람로 검출된 객체가 있음)\n",
    "        if checking_class.count(4) == 0: # 객체들의 클래스 번호가 담긴 리스트에서 4이 0개 일시\n",
    "            print('사람이 검출되지 않았습니다.')\n",
    "        else:\n",
    "            # 크기가 가장 큰 바운딩 박스 찾는 함수 호출\n",
    "            eye_yn, leg_yn, loc, mouth_yn, size, arm_yn = person_size(results, checking_class)\n",
    "    else: # 오류 방지 차원 알고리즘으로 라벨링 불가시\n",
    "        eye_yn = 'no detect'\n",
    "        leg_yn = 'no detect'\n",
    "        mouth_yn = 'no detect'\n",
    "        arm_yn = 'no detect'\n",
    "        loc = 'no detect'\n",
    "        size = 'no detect'\n",
    "\n",
    "    return eye_yn, leg_yn, loc, mouth_yn, size, arm_yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('./person_x_weight/weights/best.pt') # 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolov8_person_detect(path,filename): # 검사할 이미지의 경로와 파일 이름을 인자로\n",
    "    \n",
    "    results = model.predict(path+ '/' + filename) # 로드한 모델로부터 예측결과를 results에 할당\n",
    "    \n",
    "    res_plot = results[0].plot()\n",
    "    \n",
    "    plt.imshow(res_plot)\n",
    "\n",
    "    eye_yn, leg_yn, loc, mouth_yn, size, arm_yn = person_csv(results)\n",
    "    \n",
    "    return eye_yn, leg_yn, loc, mouth_yn, size, arm_yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_save(img_dir, save_dir):\n",
    "    \n",
    "    all_images = [f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f)) and f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    filenames = []\n",
    "\n",
    "    person_df = pd.DataFrame(columns=('id', 'eye_yn', 'leg_yn', 'loc', 'mouth_yn', 'size', 'arm_yn'))\n",
    "\n",
    "    for i in all_images:\n",
    "\n",
    "        filenames.append(i.split('.')[0][:-4])\n",
    "\n",
    "    for filename, i in tqdm(zip(all_images, filenames)):\n",
    "        eye_yn, leg_yn, loc, mouth_yn, size, arm_yn = yolov8_person_detect(img_dir, filename)\n",
    "        output_filename =save_dir + i + '.jpg'\n",
    "        plt.savefig(output_filename, format='jpg', dpi=300)\n",
    "        plt.close()\n",
    "        person_df.loc[len(person_df)] = [i, eye_yn, leg_yn, loc, mouth_yn, size, arm_yn] # 행기준으로 추가\n",
    "    \n",
    "    person_df.to_csv(save_dir +'person_result2.csv', index=False) # csv파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\24_175_23006_person_jpg.rf.690f68c11a390bc87763bb6774dfada5.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 181.8ms\n",
      "Speed: 4.0ms preprocess, 181.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "1it [00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\24_175_23007_person_jpg.rf.44e75451099fc23f6bc9f6d2fbce183b.jpg: 640x640 3 leg_yns, 2 persons, 49.0ms\n",
      "Speed: 2.0ms preprocess, 49.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "2it [00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\24_175_23015_person_jpg.rf.6a959ab6094579e28afe904fdfe35fb9.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 49.0ms\n",
      "Speed: 1.0ms preprocess, 49.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "3it [00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\24_175_23020_person_jpg.rf.04191d9db7c2583176208bd4745c0e96.jpg: 640x640 2 arm_yns, 2 eye_yns, 1 mouth_yn, 1 person, 50.0ms\n",
      "Speed: 1.0ms preprocess, 50.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "4it [00:01,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\24_177_23044_person_jpg.rf.be1f67402cb6e5d394b69d497e90d6de.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "5it [00:01,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\24_178_23068_person_jpg.rf.634996c49fdebec68d51686dd3f76cdb.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "6it [00:01,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\24_178_23073_person_jpg.rf.9044550486f8a2fa737adb30a7d0d821.jpg: 640x640 4 arm_yns, 2 leg_yns, 1 person, 48.0ms\n",
      "Speed: 1.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "7it [00:01,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\24_179_23103_person_jpg.rf.33d6f5c6cb6e81ffaf6a0246ca474fd8.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 48.0ms\n",
      "Speed: 1.0ms preprocess, 48.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "8it [00:01,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\24_180_23123_person_jpg.rf.faa650a288984c46df05cde15446808e.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 49.0ms\n",
      "Speed: 2.0ms preprocess, 49.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "9it [00:02,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\24_180_23124_person_jpg.rf.ebd56ddedd3d8c65df770f46ea6a9358.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 58.0ms\n",
      "Speed: 2.0ms preprocess, 58.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "10it [00:02,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\24_180_23136_person_jpg.rf.e88f7100abac7dbaaf2371b35d05376c.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 58.0ms\n",
      "Speed: 2.0ms preprocess, 58.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "11it [00:02,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\24_180_23140_person_jpg.rf.a5df07d0dce0bed30d05e9f8b261c33a.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 62.0ms\n",
      "Speed: 1.0ms preprocess, 62.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "12it [00:02,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\24_181_23158_person_jpg.rf.27e0e2feb803b039f246cf04b343e29f.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 58.0ms\n",
      "Speed: 1.0ms preprocess, 58.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "13it [00:03,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\26_139_23007_person_jpg.rf.b13b7ee1cdbfa7511a28b99c758d11c5.jpg: 640x640 3 arm_yns, 2 eye_yns, 4 leg_yns, 1 mouth_yn, 1 person, 62.0ms\n",
      "Speed: 1.0ms preprocess, 62.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "14it [00:03,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\26_139_23009_person_jpg.rf.bc18bc6495f30ab8227eff5e18a8a8bc.jpg: 640x640 1 arm_yn, 4 eye_yns, 3 leg_yns, 1 person, 57.0ms\n",
      "Speed: 2.0ms preprocess, 57.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "15it [00:03,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\26_140_23022_person_jpg.rf.caf4e80aa09a91f34e2537de6a032e92.jpg: 640x640 2 arm_yns, 1 eye_yn, 3 leg_yns, 1 mouth_yn, 2 persons, 55.0ms\n",
      "Speed: 2.0ms preprocess, 55.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "16it [00:03,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 6]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\26_140_23025_person_jpg.rf.37a10b5925b7360012d262bf8e02ec24.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 55.0ms\n",
      "Speed: 2.0ms preprocess, 55.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "17it [00:04,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\26_141_23036_person_jpg.rf.7a237e120b2c755bfb33f33b2056ea69.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 58.0ms\n",
      "Speed: 2.0ms preprocess, 58.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "18it [00:04,  3.82it/s]\n",
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\26_141_23038_person_jpg.rf.67ac4a9aa087569691d04a95472897ce.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 55.0ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.0ms preprocess, 55.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "19it [00:04,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_91_23005_person_jpg.rf.66b75d3d3319116bb72961387a86645c.jpg: 640x640 2 arm_yns, 2 eye_yns, 1 leg_yn, 1 person, 64.0ms\n",
      "Speed: 1.0ms preprocess, 64.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "20it [00:04,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_91_23022_person_jpg.rf.00ad5d61364b6bed5ca2978acec5b935.jpg: 640x640 2 arm_yns, 3 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "21it [00:05,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_91_23024_person_jpg.rf.96475c4b694a63393b29b3dbc5a5b526.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "22it [00:05,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_92_23032_person_jpg.rf.ec644d4c47047bf8f31c47c1aafbf01a.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 53.0ms\n",
      "Speed: 1.0ms preprocess, 53.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "23it [00:05,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_92_23040_person_jpg.rf.d23360eebc82925a7b88dd6bb4c9f560.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 63.0ms\n",
      "Speed: 2.0ms preprocess, 63.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "24it [00:05,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_93_23053_person_jpg.rf.a2714b1737a80e4cdcad7a77d488c9f0.jpg: 640x640 1 arm_yn, 1 eye_yn, 1 mouth_yn, 1 person, 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "25it [00:06,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_94_23072_person_jpg.rf.ce9a56e98bafca43937edfabc5a42c2b.jpg: 640x640 2 arm_yns, 1 leg_yn, 1 person, 59.0ms\n",
      "Speed: 1.0ms preprocess, 59.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "26it [00:06,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_94_23078_person_jpg.rf.5c74fe3e9a11ba79fe1c8b5089d98bae.jpg: 640x640 2 arm_yns, 2 eye_yns, 3 leg_yns, 1 mouth_yn, 1 person, 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "27it [00:06,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_94_23084_person_jpg.rf.785cdd4c8ad82901df9ffca0d57138c6.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 58.0ms\n",
      "Speed: 2.0ms preprocess, 58.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "28it [00:06,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_94_23085_person_jpg.rf.ad2126ebe85c0f5f436f093f25bf4f56.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 2 mouth_yns, 1 person, 52.0ms\n",
      "Speed: 2.0ms preprocess, 52.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "29it [00:07,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_95_23104_person_jpg.rf.3b8465e5ae9d0cb26e0f17437db8839b.jpg: 640x640 2 arm_yns, 2 leg_yns, 1 person, 60.0ms\n",
      "Speed: 2.0ms preprocess, 60.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "30it [00:07,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_96_23130_person_jpg.rf.33337f87fa26d23731e070058cea3e25.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 72.0ms\n",
      "Speed: 2.0ms preprocess, 72.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "31it [00:07,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_96_23134_person_jpg.rf.8cc824629eab2fcf2291109638704282.jpg: 640x640 2 arm_yns, 1 eye_yn, 2 leg_yns, 1 person, 54.0ms\n",
      "Speed: 2.0ms preprocess, 54.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "32it [00:07,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_97_23145_person_jpg.rf.de8a23cd76030edb62ade0a1441432c8.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 62.0ms\n",
      "Speed: 2.0ms preprocess, 62.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "33it [00:08,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_98_23188_person_jpg.rf.100570c426db1272108eff1f35d75280.jpg: 640x640 2 arm_yns, 2 eye_yns, 1 mouth_yn, 1 person, 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "34it [00:08,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_99_23203_person_jpg.rf.99dfdb0319b8fbf48a5cf0003c118efe.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 61.0ms\n",
      "Speed: 1.0ms preprocess, 61.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "35it [00:08,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_99_23206_person_jpg.rf.5864533312fff53f90385fc9d1cf6ecb.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 person, 54.0ms\n",
      "Speed: 2.0ms preprocess, 54.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "36it [00:08,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_99_23212_person_jpg.rf.be119fe3808319d0e58a4281d4574bc9.jpg: 640x640 2 arm_yns, 1 eye_yn, 2 leg_yns, 1 mouth_yn, 52.0ms\n",
      "Speed: 2.0ms preprocess, 52.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "37it [00:08,  4.20it/s]\n",
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_99_23220_person_jpg.rf.1b7f0da3a4142e605dc8a69a34e1a898.jpg: 640x640 2 arm_yns, 3 eye_yns, 2 leg_yns, 2 persons, 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "38it [00:09,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 8]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\33_99_23225_person_jpg.rf.301bf9d1e55416f8cfccc956c19236c1.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 59.0ms\n",
      "Speed: 2.0ms preprocess, 59.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "39it [00:09,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\38_104_23007_person_jpg.rf.65c960b20565bde638b47951347d130a.jpg: 640x640 1 arm_yn, 1 leg_yn, 1 mouth_yn, 1 person, 59.0ms\n",
      "Speed: 2.0ms preprocess, 59.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "40it [00:09,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\38_104_23008_person_jpg.rf.d13dbba462319e88d544670ca7a321f3.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 62.0ms\n",
      "Speed: 2.0ms preprocess, 62.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "41it [00:10,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\38_105_23025_person_jpg.rf.a06f26c80d46c6fc931aaebc54c58ebb.jpg: 640x640 1 arm_yn, 2 eye_yns, 2 leg_yns, 1 person, 64.0ms\n",
      "Speed: 2.0ms preprocess, 64.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "42it [00:10,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\38_106_23047_person_jpg.rf.ced0ec9ebcc6c0a10b91d666ae1f1b01.jpg: 640x640 3 arm_yns, 3 eye_yns, 3 leg_yns, 1 mouth_yn, 1 person, 63.0ms\n",
      "Speed: 2.0ms preprocess, 63.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "43it [00:10,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\38_106_23053_person_jpg.rf.1d85b02ebb5848d85702fc069f22b814.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 60.0ms\n",
      "Speed: 1.0ms preprocess, 60.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "44it [00:10,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\38_106_23066_person_jpg.rf.c962b17f8c12d29fc922406906e37c53.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "45it [00:11,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\38_107_23082_person_jpg.rf.7e7e37be22b216b3d96a452d7e73b472.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 76.0ms\n",
      "Speed: 2.0ms preprocess, 76.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "46it [00:11,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\38_107_23085_person_jpg.rf.08c41f467e345c7dd75db54d8a95b52c.jpg: 640x640 2 arm_yns, 2 eye_yns, 1 mouth_yn, 1 person, 61.0ms\n",
      "Speed: 1.0ms preprocess, 61.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "47it [00:11,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\38_107_23086_person_jpg.rf.0d67dca7fb3f36df177a0e8790ad5d9f.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 55.0ms\n",
      "Speed: 2.0ms preprocess, 55.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "48it [00:11,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_11_23078_person_jpg.rf.ef0e60df519d169e4ceb3f1452bc29e5.jpg: 640x640 2 arm_yns, 2 leg_yns, 1 person, 57.0ms\n",
      "Speed: 1.0ms preprocess, 57.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "49it [00:11,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_12_23086_person_jpg.rf.8a2641b3fb84d62be97b42fc086c5a8b.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 62.0ms\n",
      "Speed: 2.0ms preprocess, 62.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "50it [00:12,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_12_23102_person_jpg.rf.7e51ceeaf8539fa0bcf4a7cbd0392733.jpg: 640x640 2 arm_yns, 2 eye_yns, 1 mouth_yn, 1 person, 61.0ms\n",
      "Speed: 2.0ms preprocess, 61.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "51it [00:12,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_13_23103_person_jpg.rf.fde50b2257ed6f4175a254c27f59576f.jpg: 640x640 3 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 61.0ms\n",
      "Speed: 1.0ms preprocess, 61.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "52it [00:12,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_13_23105_person_jpg.rf.bae9f0a84d0b4761c16c04d74f755049.jpg: 640x640 3 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 2 persons, 57.0ms\n",
      "Speed: 1.0ms preprocess, 57.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "53it [00:12,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 8]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_13_23106_person_jpg.rf.fdcbc12b1bd0ff51e893370a7e0e081b.jpg: 640x640 1 arm_yn, 1 eye_yn, 5 leg_yns, 1 person, 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "54it [00:13,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_13_23108_person_jpg.rf.3f662fc4eae15b07a5613a031f7ce9eb.jpg: 640x640 1 arm_yn, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 55.0ms\n",
      "Speed: 1.0ms preprocess, 55.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "55it [00:13,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_13_23120_person_jpg.rf.52da662c6ad7aca2966c7ccfbcaa9c00.jpg: 640x640 2 arm_yns, 2 eye_yns, 3 leg_yns, 2 persons, 57.0ms\n",
      "Speed: 2.0ms preprocess, 57.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "56it [00:13,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 8]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_14_23018_person_jpg.rf.67095daf6cd53f68339c5dce08f0d621.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 58.0ms\n",
      "Speed: 1.0ms preprocess, 58.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "57it [00:13,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_15_23029_person_jpg.rf.fe733fb6f964a89612cd9987b573cac2.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 55.0ms\n",
      "Speed: 2.0ms preprocess, 55.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "58it [00:14,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_15_23036_person_jpg.rf.197a5c2326ba55a68aace62b1cd94153.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 55.0ms\n",
      "Speed: 2.0ms preprocess, 55.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "59it [00:14,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_16_23045_person_jpg.rf.e4d3b75a3982b8bd3b5da23d1400b5c1.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 54.0ms\n",
      "Speed: 2.0ms preprocess, 54.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "60it [00:14,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_16_23049_person_jpg.rf.52d38b8007cc236764a1d198fbab2719.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 person, 56.0ms\n",
      "Speed: 1.0ms preprocess, 56.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "61it [00:14,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\3_16_23058_person_jpg.rf.78b9ab1e9c177b680f69fa5d20adff65.jpg: 640x640 3 eye_yns, 3 leg_yns, 1 mouth_yn, 2 persons, 57.0ms\n",
      "Speed: 2.0ms preprocess, 57.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "62it [00:15,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 7]\n",
      "가장 큰 바운딩 박스의 인덱스: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\47_197_23006_person_jpg.rf.8d90891509bb44d972cabecf93e01b63.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 54.0ms\n",
      "Speed: 1.0ms preprocess, 54.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "63it [00:15,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\47_198_23018_person_jpg.rf.2f070821f39c7c0a023800abd5659660.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "64it [00:15,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\47_198_23022_person_jpg.rf.ce94c95a28df86aac97c2c58efedc109.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 55.0ms\n",
      "Speed: 2.0ms preprocess, 55.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "65it [00:15,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\47_198_23024_person_jpg.rf.630377d26ff77bf5bfb536b19a83f3a6.jpg: 640x640 2 arm_yns, 1 eye_yn, 2 leg_yns, 1 mouth_yn, 1 person, 54.0ms\n",
      "Speed: 2.0ms preprocess, 54.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "66it [00:16,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_227_23006_person_jpg.rf.346a95d88a3517c8d0f66d5c3bf8e92c.jpg: 640x640 2 arm_yns, 3 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67it [00:16,  3.60it/s]\n",
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_227_23007_person_jpg.rf.288a4b6f26403e4284c2e1dab13673df.jpg: 640x640 1 arm_yn, 2 leg_yns, 1 person, 57.0ms\n",
      "Speed: 2.0ms preprocess, 57.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "68it [00:16,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_227_23009_person_jpg.rf.bac4582e561030d22e54db047f3bdcee.jpg: 640x640 2 arm_yns, 2 eye_yns, 1 leg_yn, 1 mouth_yn, 1 person, 55.0ms\n",
      "Speed: 2.0ms preprocess, 55.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "69it [00:16,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_227_23013_person_jpg.rf.aa62f04dc2e3ea7db9835168bb671fe1.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 51.0ms\n",
      "Speed: 1.0ms preprocess, 51.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "70it [00:17,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_228_23033_person_jpg.rf.f3fe6b3d4e4209bf11c5b7dd7655a226.jpg: 640x640 2 arm_yns, 1 eye_yn, 1 mouth_yn, 1 person, 58.0ms\n",
      "Speed: 1.0ms preprocess, 58.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "71it [00:17,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_228_23040_person_jpg.rf.c852709ef30c929f487aceb219aaa9ca.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 54.0ms\n",
      "Speed: 2.0ms preprocess, 54.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "72it [00:17,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_229_23063_person_jpg.rf.ed0be8c6f48249869fd3ce5a4a1999f7.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 person, 55.0ms\n",
      "Speed: 1.0ms preprocess, 55.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "73it [00:17,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_229_23071_person_jpg.rf.6a00a30a47507b79473c7192a7cb625f.jpg: 640x640 2 eye_yns, 1 leg_yn, 1 person, 60.0ms\n",
      "Speed: 2.0ms preprocess, 60.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "74it [00:18,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_230_23072_person_jpg.rf.79da3c8e51d9e97ba30a1294f2cc4819.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 58.0ms\n",
      "Speed: 2.0ms preprocess, 58.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "75it [00:18,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_230_23075_person_jpg.rf.daac510ed25a5be1498d11140f2ba9ff.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 49.0ms\n",
      "Speed: 1.0ms preprocess, 49.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "76it [00:18,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_230_23085_person_jpg.rf.06361610ae9cb30f836c15ce580bf895.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 61.0ms\n",
      "Speed: 1.0ms preprocess, 61.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "77it [00:18,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_230_23090_person_jpg.rf.b3faec1475c20fe725cf9692e19e1813.jpg: 640x640 2 arm_yns, 2 eye_yns, 5 leg_yns, 1 mouth_yn, 1 person, 57.0ms\n",
      "Speed: 2.0ms preprocess, 57.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "78it [00:19,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_230_23092_person_jpg.rf.d8b3a74a70d0f4c42b5fa5e52b11dc64.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 59.0ms\n",
      "Speed: 1.0ms preprocess, 59.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "79it [00:19,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\50_231_23105_person_jpg.rf.5c6eebdfc2d57b619b73bea89af8329b.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 58.0ms\n",
      "Speed: 1.0ms preprocess, 58.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "80it [00:19,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\52_214_23005_person_jpg.rf.d14553b0c8279384facaaad8dfa0ee7d.jpg: 640x640 2 arm_yns, 3 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 61.0ms\n",
      "Speed: 2.0ms preprocess, 61.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "81it [00:19,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\52_214_23010_person_jpg.rf.a165d47b3cdf87f97e9ee21d20fe8286.jpg: 640x640 2 arm_yns, 2 leg_yns, 1 person, 57.0ms\n",
      "Speed: 2.0ms preprocess, 57.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "82it [00:20,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\52_216_23044_person_jpg.rf.14911dd2b65700998048cdbf52ce5812.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 64.0ms\n",
      "Speed: 2.0ms preprocess, 64.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "83it [00:20,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\52_216_23048_person_jpg.rf.32620a27192503e644d5472bff9b6566.jpg: 640x640 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 65.0ms\n",
      "Speed: 2.0ms preprocess, 65.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "84it [00:20,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\52_216_23050_person_jpg.rf.4d5fb3b1a1e26a3ae0513a50a9240d78.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 54.0ms\n",
      "Speed: 2.0ms preprocess, 54.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "85it [00:20,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\52_216_23051_person_jpg.rf.c7e10262c1c689e19c1c4bd762419e85.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "86it [00:20,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\52_216_23053_person_jpg.rf.c1196a8f0442228f8cce9cb5cf69f70e.jpg: 640x640 2 arm_yns, 1 eye_yn, 2 leg_yns, 1 mouth_yn, 1 person, 52.0ms\n",
      "Speed: 1.0ms preprocess, 52.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "87it [00:21,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\52_217_23065_person_jpg.rf.6ee546b7263a34a41f1fc724f4e897ce.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 52.0ms\n",
      "Speed: 2.0ms preprocess, 52.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "88it [00:21,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\52_217_23070_person_jpg.rf.bc59257f147fb5e9a47408cccb0f500b.jpg: 640x640 3 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 53.0ms\n",
      "Speed: 1.0ms preprocess, 53.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "89it [00:21,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\52_217_23071_person_jpg.rf.eb3336ccb318e326a5d1da433f2b598f.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "90it [00:21,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\52_218_23113_person_jpg.rf.1000403037e908f3fac47a718307b78a.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 53.0ms\n",
      "Speed: 1.0ms preprocess, 53.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "91it [00:22,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\52_218_23117_person_jpg.rf.132c193f1266ff06621edff3f3a3eea2.jpg: 640x640 2 arm_yns, 2 leg_yns, 1 mouth_yn, 1 person, 54.0ms\n",
      "Speed: 1.0ms preprocess, 54.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "92it [00:22,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\52_219_23083_person_jpg.rf.bcbb8b1ebe23e53123b722bc74a82da7.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 58.0ms\n",
      "Speed: 2.0ms preprocess, 58.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "93it [00:22,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\5_25_23046_person_jpg.rf.919cddf0b5f807b9f7b1dfb09a70b7b7.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 59.0ms\n",
      "Speed: 2.0ms preprocess, 59.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "94it [00:22,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\5_25_23048_person_jpg.rf.b85a473fa147025e3603d4114872978a.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 61.0ms\n",
      "Speed: 2.0ms preprocess, 61.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "95it [00:23,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\5_29_23031_person_jpg.rf.795b3f7569d2db40f1d850fe00707c42.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 58.0ms\n",
      "Speed: 1.0ms preprocess, 58.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "96it [00:23,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\5_29_23033_person_jpg.rf.8d15844094a00aee9796344bd34c2ff8.jpg: 640x640 2 arm_yns, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 58.0ms\n",
      "Speed: 2.0ms preprocess, 58.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "97it [00:23,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\5_29_23034_person_jpg.rf.d1ac173b36f84babc809576bd5abeaa8.jpg: 640x640 1 arm_yn, 2 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 59.0ms\n",
      "Speed: 1.0ms preprocess, 59.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "98it [00:23,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\yolov8\\person.v1i.yolov8\\test\\images\\5_29_23035_person_jpg.rf.fc2a47fb1203dcd10454cdcc501dc3e9.jpg: 640x640 2 arm_yns, 3 eye_yns, 2 leg_yns, 1 mouth_yn, 1 person, 57.0ms\n",
      "Speed: 1.0ms preprocess, 57.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "99it [00:24,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "가장 큰 바운딩 박스의 인덱스: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "person_save(img_dir='./person.v1i.yolov8/test/images', save_dir= './person_result/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eye diff : 9\n",
      "leg diff : 7\n",
      "mouth diff : 25\n",
      "arm diff : 8\n",
      "loc diff : 6\n",
      "size diff : 21\n"
     ]
    }
   ],
   "source": [
    "person_ori_df = pd.read_csv('./dbi_person.csv')\n",
    "person_pred_df = pd.read_csv('./person_result/person_result2.csv')\n",
    "person_ori_100_df = person_ori_df[person_ori_df['id'].isin(person_pred_df['id'])]\n",
    "\n",
    "eye_count = 0\n",
    "leg_count = 0\n",
    "mouth_count = 0\n",
    "arm_count = 0\n",
    "loc_count = 0\n",
    "size_count = 0\n",
    "\n",
    "for i in range(len(person_pred_df)):\n",
    "    if person_ori_100_df['eye_yn'].tolist()[i] != person_pred_df['eye_yn'].tolist()[i]:\n",
    "        eye_count += 1\n",
    "    if person_ori_100_df['leg_yn'].tolist()[i] != person_pred_df['leg_yn'].tolist()[i]:\n",
    "        leg_count += 1\n",
    "    if person_ori_100_df['mouth_yn'].tolist()[i] != person_pred_df['mouth_yn'].tolist()[i]:\n",
    "        mouth_count += 1\n",
    "    if person_ori_100_df['arm_yn'].tolist()[i] != person_pred_df['arm_yn'].tolist()[i]:\n",
    "        arm_count += 1\n",
    "    if person_ori_100_df['loc'].tolist()[i] != person_pred_df['loc'].tolist()[i]:\n",
    "        loc_count += 1\n",
    "    if person_ori_100_df['size'].tolist()[i] != person_pred_df['size'].tolist()[i]:\n",
    "        size_count += 1\n",
    "\n",
    "print(f'eye diff : {eye_count}')\n",
    "print(f'leg diff : {leg_count}')\n",
    "print(f'mouth diff : {mouth_count}')\n",
    "print(f'arm diff : {arm_count}')\n",
    "print(f'loc diff : {loc_count}')\n",
    "print(f'size diff : {size_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "['33_94_23072_person', 'y', 'n']\n",
      "['33_95_23104_person', 'y', 'n']\n",
      "['33_99_23212_person', 'y', 'no detect']\n",
      "['3_11_23078_person', 'y', 'n']\n",
      "['3_16_23058_person', 'y', 'n']\n",
      "['52_216_23044_person', 'n', 'y']\n",
      "['52_216_23050_person', 'n', 'y']\n",
      "['52_216_23051_person', 'n', 'y']\n",
      "['52_216_23053_person', 'n', 'y']\n"
     ]
    }
   ],
   "source": [
    "eye_wrong = []\n",
    "for i in range(len(person_pred_df)): \n",
    "    if person_ori_100_df['eye_yn'].iloc[i] != person_pred_df['eye_yn'].iloc[i]:\n",
    "        eye_wrong.append([person_pred_df['id'].iloc[i], person_ori_100_df['eye_yn'].iloc[i], person_pred_df['eye_yn'].iloc[i]])\n",
    "\n",
    "print(len(eye_wrong))\n",
    "for i in eye_wrong:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "['24_175_23020_person', 'y', 'n']\n",
      "['33_93_23053_person', 'y', 'n']\n",
      "['33_99_23212_person', 'n', 'no detect']\n",
      "['38_107_23085_person', 'y', 'n']\n",
      "['3_12_23102_person', 'y', 'n']\n",
      "['50_227_23009_person', 'n', 'y']\n",
      "['52_218_23113_person', 'n', 'y']\n"
     ]
    }
   ],
   "source": [
    "leg_wrong = []\n",
    "for i in range(len(person_pred_df)): \n",
    "    if person_ori_100_df['leg_yn'].iloc[i] != person_pred_df['leg_yn'].iloc[i]:\n",
    "        leg_wrong.append([person_pred_df['id'].iloc[i], person_ori_100_df['leg_yn'].iloc[i], person_pred_df['leg_yn'].iloc[i]])\n",
    "\n",
    "print(len(leg_wrong))\n",
    "for i in leg_wrong:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "['26_139_23009_person', 'y', 'n']\n",
      "['33_91_23005_person', 'y', 'n']\n",
      "['33_94_23072_person', 'y', 'n']\n",
      "['33_95_23104_person', 'y', 'n']\n",
      "['33_99_23206_person', 'y', 'n']\n",
      "['33_99_23212_person', 'y', 'no detect']\n",
      "['33_99_23220_person', 'y', 'n']\n",
      "['38_104_23007_person', 'n', 'y']\n",
      "['38_105_23025_person', 'y', 'n']\n",
      "['3_11_23078_person', 'y', 'n']\n",
      "['3_13_23106_person', 'y', 'n']\n",
      "['3_13_23120_person', 'y', 'n']\n",
      "['3_16_23049_person', 'y', 'n']\n",
      "['3_16_23058_person', 'y', 'n']\n",
      "['50_227_23006_person', 'n', 'y']\n",
      "['50_227_23007_person', 'y', 'n']\n",
      "['50_227_23013_person', 'n', 'y']\n",
      "['50_228_23033_person', 'n', 'y']\n",
      "['50_228_23040_person', 'n', 'y']\n",
      "['50_229_23063_person', 'y', 'n']\n",
      "['50_229_23071_person', 'y', 'n']\n",
      "['50_231_23105_person', 'n', 'y']\n",
      "['52_216_23048_person', 'n', 'y']\n",
      "['52_217_23065_person', 'n', 'y']\n",
      "['5_29_23031_person', 'n', 'y']\n"
     ]
    }
   ],
   "source": [
    "mouth_wrong = []\n",
    "for i in range(len(person_pred_df)): \n",
    "    if person_ori_100_df['mouth_yn'].iloc[i] != person_pred_df['mouth_yn'].iloc[i]:\n",
    "        mouth_wrong.append([person_pred_df['id'].iloc[i], person_ori_100_df['mouth_yn'].iloc[i], person_pred_df['mouth_yn'].iloc[i]])\n",
    "\n",
    "print(len(mouth_wrong))\n",
    "for i in mouth_wrong:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "['33_99_23212_person', 'n', 'no detect']\n",
      "['3_13_23106_person', 'n', 'y']\n",
      "['3_13_23108_person', 'n', 'y']\n",
      "['3_16_23058_person', 'y', 'n']\n",
      "['50_229_23071_person', 'y', 'n']\n",
      "['50_230_23072_person', 'n', 'y']\n",
      "['52_216_23048_person', 'y', 'n']\n",
      "['52_218_23117_person', 'n', 'y']\n"
     ]
    }
   ],
   "source": [
    "arm_wrong = []\n",
    "for i in range(len(person_pred_df)): \n",
    "    if person_ori_100_df['arm_yn'].iloc[i] != person_pred_df['arm_yn'].iloc[i]:\n",
    "        arm_wrong.append([person_pred_df['id'].iloc[i], person_ori_100_df['arm_yn'].iloc[i], person_pred_df['arm_yn'].iloc[i]])\n",
    "\n",
    "print(len(arm_wrong))\n",
    "for i in arm_wrong:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['24_175_23006_person', 'right', 'center']\n",
      "['24_175_23007_person', 'center', 'right']\n",
      "['24_175_23020_person', 'left', 'center']\n",
      "['33_94_23085_person', 'left', 'center']\n",
      "['33_99_23212_person', 'left', 'no detect']\n",
      "['3_11_23078_person', 'right', 'center']\n"
     ]
    }
   ],
   "source": [
    "loc_wrong = []\n",
    "for i in range(len(person_pred_df)): \n",
    "    if person_ori_100_df['loc'].iloc[i] != person_pred_df['loc'].iloc[i]:\n",
    "        loc_wrong.append([person_pred_df['id'].iloc[i], person_ori_100_df['loc'].iloc[i], person_pred_df['loc'].iloc[i]])\n",
    "\n",
    "print(len(loc_wrong))\n",
    "for i in loc_wrong:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "['24_175_23007_person', 'small', 'big']\n",
      "['24_177_23044_person', 'small', 'middle']\n",
      "['26_140_23025_person', 'middle', 'big']\n",
      "['33_91_23005_person', 'middle', 'big']\n",
      "['33_91_23022_person', 'big', 'middle']\n",
      "['33_94_23084_person', 'middle', 'small']\n",
      "['33_96_23130_person', 'big', 'middle']\n",
      "['33_99_23212_person', 'middle', 'no detect']\n",
      "['33_99_23220_person', 'big', 'middle']\n",
      "['33_99_23225_person', 'small', 'middle']\n",
      "['38_106_23053_person', 'middle', 'big']\n",
      "['3_13_23120_person', 'small', 'big']\n",
      "['47_198_23024_person', 'middle', 'small']\n",
      "['50_227_23009_person', 'small', 'middle']\n",
      "['50_229_23063_person', 'big', 'middle']\n",
      "['50_230_23072_person', 'middle', 'small']\n",
      "['50_230_23075_person', 'middle', 'big']\n",
      "['50_230_23092_person', 'big', 'middle']\n",
      "['52_216_23051_person', 'middle', 'small']\n",
      "['52_216_23053_person', 'big', 'middle']\n",
      "['52_219_23083_person', 'big', 'middle']\n"
     ]
    }
   ],
   "source": [
    "size_wrong = []\n",
    "for i in range(len(person_pred_df)): \n",
    "    if person_ori_100_df['size'].iloc[i] != person_pred_df['size'].iloc[i]:\n",
    "        size_wrong.append([person_pred_df['id'].iloc[i], person_ori_100_df['size'].iloc[i], person_pred_df['size'].iloc[i]])\n",
    "\n",
    "print(len(size_wrong))\n",
    "for i in size_wrong:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
